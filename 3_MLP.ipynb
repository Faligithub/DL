{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Design, train and test the MLP for tabular data and verify various activation functions and optimizers tensor flow"
      ],
      "metadata": {
        "id": "zHDg1MZQInC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description: In this python Program we load the breast cancer dataset and split it into training and test sets. We define a function create_model that takes an\n",
        "activation function and optimizer as arguments and returns an MLP with two\n",
        "hidden layers and dropout regularization. We then define a list of activation\n",
        "functions and optimizers to try, and loop over them to train and test models\n",
        "with different combinations of activation functions and optimizers. We print\n",
        "the test loss and accuracy for each model."
      ],
      "metadata": {
        "id": "LLIIKHdiI5IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.activations import relu, sigmoid, tanh\n",
        "\n",
        "# load the data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,\n",
        "test_size=0.2, random_state=42)\n",
        "\n",
        "# define the model\n",
        "def create_model(activation_func, optimizer):\n",
        "  model = Sequential([\n",
        "      Dense(64, input_dim=X_train.shape[1], activation=activation_func),\n",
        "      Dropout(0.5),\n",
        "      Dense(32, activation=activation_func),\n",
        "      Dropout(0.5),\n",
        "      Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# define the activation functions and optimizers to try\n",
        "activation_funcs = [relu, sigmoid, tanh]\n",
        "optimizer_classes = [SGD, Adam, RMSprop]\n",
        "\n",
        "# train and test the models with different activation functions and optimizers\n",
        "for activation_func in activation_funcs:\n",
        "    for optimizer_class in optimizer_classes:\n",
        "        # Create a new instance of the optimizer for each model\n",
        "        optimizer = optimizer_class(learning_rate=0.001)\n",
        "        model = create_model(activation_func, optimizer)\n",
        "\n",
        "        print(f'Training model with activation function {activation_func.__name__} and optimizer {optimizer.__class__.__name__}...')\n",
        "        model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "        loss, accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjqUgj7BKZzy",
        "outputId": "5db83835-8660-400f-fa39-70ca1ed7848a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with activation function relu and optimizer SGD...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.4322  \n",
            "Test loss: 0.423, Test accuracy: 0.895\n",
            "\n",
            "Training model with activation function relu and optimizer Adam...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.4196  \n",
            "Test loss: 0.422, Test accuracy: 0.912\n",
            "\n",
            "Training model with activation function relu and optimizer RMSprop...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.2124  \n",
            "Test loss: 0.215, Test accuracy: 0.956\n",
            "\n",
            "Training model with activation function sigmoid and optimizer SGD...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6377 - loss: 0.6199  \n",
            "Test loss: 0.627, Test accuracy: 0.623\n",
            "\n",
            "Training model with activation function sigmoid and optimizer Adam...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2108  \n",
            "Test loss: 0.203, Test accuracy: 0.947\n",
            "\n",
            "Training model with activation function sigmoid and optimizer RMSprop...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1848  \n",
            "Test loss: 0.177, Test accuracy: 0.939\n",
            "\n",
            "Training model with activation function tanh and optimizer SGD...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6377 - loss: 0.5725  \n",
            "Test loss: 0.584, Test accuracy: 0.623\n",
            "\n",
            "Training model with activation function tanh and optimizer Adam...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1702  \n",
            "Test loss: 0.156, Test accuracy: 0.939\n",
            "\n",
            "Training model with activation function tanh and optimizer RMSprop...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2149  \n",
            "Test loss: 0.194, Test accuracy: 0.947\n",
            "\n"
          ]
        }
      ]
    }
  ]
}