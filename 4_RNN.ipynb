{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Design and implement a simple RNN model with tensorflow / keras and check accuracy"
      ],
      "metadata": {
        "id": "zHDg1MZQInC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description: This program demonstrates the design and implementation of a simple Recurrent Neural Network (RNN) using TensorFlow and Keras. It utilizes the MNIST dataset, a collection of handwritten digits, for classification. The model consists of a reshaped input layer, an LSTM (Long Short-Term Memory) layer for capturing sequential patterns, and a dense softmax layer for final classification. The code normalizes the input data, applies one-hot encoding to the labels, and then trains the model using the Adam optimizer. The model's performance is evaluated on test data, and the test loss and accuracy are printed after training."
      ],
      "metadata": {
        "id": "LLIIKHdiI5IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Next, let's load the MNIST dataset:\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Now, we need to normalize the input data and convert the labels to one-hot encoding:(0-255 prxels are normalized to 0-1) for better\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "#Let's define the hyperparameters:\n",
        "input_shape = (28, 28)\n",
        "num_classes = 10\n",
        "hidden_size = 128\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "#Now, let's define the RNN model:\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Input(shape=input_shape),\n",
        "tf.keras.layers.Reshape(target_shape=(input_shape[0],\n",
        "input_shape[1]*1)),\n",
        "tf.keras.layers.LSTM(units=hidden_size, activation='tanh'),\n",
        "tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\"\"\"The model consists of an LSTM layer followed by a dense layer with a\n",
        "softmax activation function.\n",
        "Now, let's compile the model:\n",
        "\"\"\"\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=tf.keras.optimizers.Adam(),\n",
        "metrics=['accuracy'])\n",
        "\n",
        "#Finally, let's train the model:\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "#After training, we can evaluate the accuracy of the model on the test data:\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeJAsMXfLHIz",
        "outputId": "59f63717-1e19-44ca-831a-13d91012f24b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 86ms/step - accuracy: 0.6641 - loss: 0.9836 - val_accuracy: 0.9398 - val_loss: 0.1900\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9506 - loss: 0.1610 - val_accuracy: 0.9616 - val_loss: 0.1240\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 87ms/step - accuracy: 0.9694 - loss: 0.1015 - val_accuracy: 0.9663 - val_loss: 0.1089\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9777 - loss: 0.0727 - val_accuracy: 0.9708 - val_loss: 0.0947\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9810 - loss: 0.0620 - val_accuracy: 0.9800 - val_loss: 0.0642\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9851 - loss: 0.0487 - val_accuracy: 0.9793 - val_loss: 0.0687\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 88ms/step - accuracy: 0.9868 - loss: 0.0427 - val_accuracy: 0.9799 - val_loss: 0.0646\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 88ms/step - accuracy: 0.9881 - loss: 0.0386 - val_accuracy: 0.9811 - val_loss: 0.0623\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 94ms/step - accuracy: 0.9895 - loss: 0.0328 - val_accuracy: 0.9808 - val_loss: 0.0594\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 86ms/step - accuracy: 0.9906 - loss: 0.0296 - val_accuracy: 0.9841 - val_loss: 0.0514\n",
            "Test loss: 0.05140664055943489\n",
            "Test accuracy: 0.9840999841690063\n"
          ]
        }
      ]
    }
  ]
}